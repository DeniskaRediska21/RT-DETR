{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f13be90e-70c6-4eba-aef9-cb9009552d84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T14:56:32.945798Z",
     "iopub.status.busy": "2024-10-28T14:56:32.945620Z",
     "iopub.status.idle": "2024-10-28T14:56:33.589180Z",
     "shell.execute_reply": "2024-10-28T14:56:33.587448Z",
     "shell.execute_reply.started": "2024-10-28T14:56:32.945777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: natsort in /home/user/LIZA/upgreat_detector/.venv/lib/python3.10/site-packages (8.4.0)\n",
      "Requirement already satisfied: tqdm in /home/user/LIZA/upgreat_detector/.venv/lib/python3.10/site-packages (4.66.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install natsort tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64318689-7fb6-4e57-a32d-4cf9d7deb67c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T14:56:33.591428Z",
     "iopub.status.busy": "2024-10-28T14:56:33.590910Z",
     "iopub.status.idle": "2024-10-28T14:56:34.851198Z",
     "shell.execute_reply": "2024-10-28T14:56:34.850698Z",
     "shell.execute_reply.started": "2024-10-28T14:56:33.591376Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import re\n",
    "from random import shuffle\n",
    "\n",
    "import torch\n",
    "from torchvision.io import decode_image, write_jpeg\n",
    "from natsort import natsorted\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63e9d831-6469-4118-9cfb-37778fd9d430",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T14:56:34.852094Z",
     "iopub.status.busy": "2024-10-28T14:56:34.851963Z",
     "iopub.status.idle": "2024-10-28T14:56:34.916851Z",
     "shell.execute_reply": "2024-10-28T14:56:34.916415Z",
     "shell.execute_reply.started": "2024-10-28T14:56:34.852084Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.join(os.sep, 'ml', 'LIZA_dataset', '**')\n",
    "OUTPUT_PATH = os.path.join(os.sep, 'ml', 'LIZA_dataset_split')\n",
    "if os.path.isdir(OUTPUT_PATH):\n",
    "    files = glob.glob(os.path.join(OUTPUT_PATH, '**'))\n",
    "    for file in files:\n",
    "        os.remove(file)\n",
    "else:\n",
    "    os.mkdir(OUTPUT_PATH)\n",
    "\n",
    "INFERENCE_SIZE = 640\n",
    "STEP_SIZE = 580"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58594dc2-7d47-48c3-87e2-f31ad244bc05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T14:56:34.917387Z",
     "iopub.status.busy": "2024-10-28T14:56:34.917248Z",
     "iopub.status.idle": "2024-10-28T14:56:36.205166Z",
     "shell.execute_reply": "2024-10-28T14:56:36.204729Z",
     "shell.execute_reply.started": "2024-10-28T14:56:34.917377Z"
    }
   },
   "outputs": [],
   "source": [
    "images = [file for file in glob.glob(os.path.join(DATASET_PATH, '*'), recursive=True) if re.match(r'(.*\\.jpg)|(.*\\.JPG)', file)]\n",
    "annotations = [file for file in glob.glob(os.path.join(DATASET_PATH, '*'), recursive=True) if re.match(r'(.*\\.txt)', file)]\n",
    "\n",
    "images = natsorted(images)\n",
    "annotations = natsorted(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2517143a-279a-4495-bd78-a64fc0654c31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T14:56:36.205757Z",
     "iopub.status.busy": "2024-10-28T14:56:36.205599Z",
     "iopub.status.idle": "2024-10-28T14:56:36.209411Z",
     "shell.execute_reply": "2024-10-28T14:56:36.209183Z",
     "shell.execute_reply.started": "2024-10-28T14:56:36.205746Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60295, 60295)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images), len(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "392f5d06-f31b-4dbe-bdf5-9f2f8dea20bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T14:56:36.209775Z",
     "iopub.status.busy": "2024-10-28T14:56:36.209684Z",
     "iopub.status.idle": "2024-10-28T16:46:58.102533Z",
     "shell.execute_reply": "2024-10-28T16:46:58.102209Z",
     "shell.execute_reply.started": "2024-10-28T14:56:36.209766Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60295it [1:50:21,  9.11it/s]\n"
     ]
    }
   ],
   "source": [
    "annotated = 0\n",
    "\n",
    "unannotated_images = []\n",
    "unannotated_annotations = []\n",
    "\n",
    "for image, annotation in tqdm(zip(images, annotations)):\n",
    "    if Path(image).stem != Path(annotation).stem:\n",
    "        raise ValueError('Images and annotations indices do not match')\n",
    "    stem = Path(image).stem\n",
    "\n",
    "    T = decode_image(image)\n",
    "    _, height, width = T.shape\n",
    "\n",
    "    \n",
    "    with open(annotation) as file:\n",
    "        labels = file.read().splitlines()\n",
    "\n",
    "    bboxes = torch.empty((len(labels), 4), dtype=torch.float32)\n",
    "    for i in range(len(labels)):\n",
    "        if not labels[i]:\n",
    "            continue\n",
    "            \n",
    "        _, bbox_x, bbox_y, bbox_w, bbox_h = labels[i].split(' ')\n",
    "        bbox_x, bbox_y, bbox_w, bbox_h = list(map(float, (bbox_x, bbox_y, bbox_w, bbox_h)))\n",
    "        \n",
    "        bbox_l = bbox_x - bbox_w / 2  # from center coordinate to left\n",
    "        bbox_t = bbox_y - bbox_h / 2  # from center coordinate to top\n",
    "        bboxes[i] = torch.as_tensor((bbox_l * width, bbox_t * height, bbox_w * width, bbox_h * height))\n",
    "\n",
    "    idx = 0\n",
    "\n",
    "    for y in range(0, height, STEP_SIZE):\n",
    "        h = min(INFERENCE_SIZE, height - y)\n",
    "        for x in range(0, width, STEP_SIZE):\n",
    "            w = min(INFERENCE_SIZE, width - x)\n",
    "            \n",
    "            window = torch.zeros((3, INFERENCE_SIZE, INFERENCE_SIZE), dtype=T.dtype)\n",
    "            window[:, :h, :w] = T[:, y:y + h, x:x + w]\n",
    "\n",
    "            window_labels = []\n",
    "            for i in range(bboxes.shape[0]):\n",
    "                l, t, w_, h_ = bboxes[i]\n",
    "                l, t, w_, h_ = l.item(), t.item(), w_.item(), h_.item()\n",
    "\n",
    "                bbox = [\n",
    "                    max(0., l - x),\n",
    "                    max(0., t - y),\n",
    "                    min(w, w_ + l - x) - max(0., l - x),\n",
    "                    min(h, h_ + t - y) - max(0., t - y)\n",
    "                ]\n",
    "\n",
    "                if bbox[2] > 0. and bbox[3] > 0.:\n",
    "                    label = f'0 {(bbox[0] + bbox[2] / 2) / INFERENCE_SIZE} {(bbox[1] + bbox[3] / 2) / INFERENCE_SIZE} {bbox[2] / INFERENCE_SIZE} {bbox[3] / INFERENCE_SIZE}'\n",
    "                    window_labels.append(label)\n",
    "\n",
    "            image_path = os.path.join(OUTPUT_PATH, f'{stem}_{idx}.jpg')\n",
    "            annotation_path = os.path.join(OUTPUT_PATH, f'{stem}_{idx}.txt')\n",
    "                \n",
    "            idx += 1\n",
    "\n",
    "            if window_labels:\n",
    "                annotated += 1\n",
    "            else:\n",
    "                unannotated_images.append(image_path)\n",
    "                unannotated_annotations.append(annotation_path)\n",
    "\n",
    "            with open(annotation_path, 'w') as file:\n",
    "                    for window_label in window_labels:\n",
    "                        file.write(f\"{window_label}\\n\")\n",
    "                \n",
    "            write_jpeg(window, image_path)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e92a734-f2b4-4828-990d-f3ec0496b26d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T16:46:58.103067Z",
     "iopub.status.busy": "2024-10-28T16:46:58.102919Z",
     "iopub.status.idle": "2024-10-28T16:46:58.114163Z",
     "shell.execute_reply": "2024-10-28T16:46:58.113919Z",
     "shell.execute_reply.started": "2024-10-28T16:46:58.103055Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2514974, 2514974)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unannotated_images), len(unannotated_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "883b6263-30d1-4f3c-8ff4-90cd0715a9b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T16:50:53.941218Z",
     "iopub.status.busy": "2024-10-28T16:50:53.940612Z",
     "iopub.status.idle": "2024-10-28T16:51:21.344168Z",
     "shell.execute_reply": "2024-10-28T16:51:21.343663Z",
     "shell.execute_reply.started": "2024-10-28T16:50:53.941171Z"
    }
   },
   "outputs": [],
   "source": [
    "ratio = 2.  # how many times there should be more unannotated images than annoted? e.g. ratio of 2 means there will be 2 unannotated for 1 annotated\n",
    "\n",
    "L = list(zip(unannotated_images, unannotated_annotations))\n",
    "shuffle(L)\n",
    "remove_images, remove_annotations = zip(*L)\n",
    "\n",
    "remove_images = remove_images[int(ratio * annotated) + 1:]\n",
    "remove_annotations = remove_annotations[int(ratio * annotated) + 1:]\n",
    "for remove_image, remove_annotations in zip(remove_images, remove_annotations):\n",
    "    for file in (remove_image, remove_annotations):\n",
    "        if os.path.exists(file):\n",
    "            os.remove(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
